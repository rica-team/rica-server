# RiCA: Multi-threaded Reasoning for Large Language Models

> Since OpenAI released ChatGPT, Large Language Models (LLMs) have become an integral part of our lives. From GPT to
> Gemini,
> from Claude to Grok, with the development of technologies like Function Calling and MCP, we are gradually moving
> towards AGI.
> However, even today, large models are still confined to a "single-threaded thinking" mode.
>
> Looking at human thought processes, searching for information and acquiring knowledge doesn't interrupt our thinking.
> Essentially, querying large models is also a form of "information lookup". Based on this insight, we developed
> Reasoning in Comprehensive Area (RiCA), aiming to introduce "multi-threading" capabilities to large models.

Today, we bring you RiCA's first demonstration set, including an Example that gives you a preliminary understanding of
RiCA's
coding principles. We will release our first usable Beta as early as this week. Additionally, we will also bring you
RiCA's
demo video. Thank you for your support!

