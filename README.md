# RiCA: Multi-threaded Reasoning for Large Language Models

> Since OpenAI released ChatGPT, Large Language Models (LLMs) have become an integral part of our lives. From GPT to
> Gemini,from Claude to Grok, with the development of technologies like Function Calling and MCP, we are gradually
> moving towards AGI. However, even today, large models are still confined to a "single-threaded thinking" mode.
>
> Looking at human thought processes, searching for information and acquiring knowledge doesn't interrupt our thinking.
> Essentially, querying large models is also a form of "information lookup". Based on this insight, we developed
> Reasoning in Comprehensive Area (RiCA), aiming to introduce "multi-threading" capabilities to large models.

~~Today, we bring you RiCA's first demonstration set, including an Example that gives you a preliminary understanding of
RiCA's coding principles. We will release our first usable Beta as early as this week. Additionally, we will also bring
you RiCA's demo video. Thank you for your support!~~

~~Now, the project is closing to completion. We have given a demo on demo/example.py. Thanks for your support! It seems
that only connections (adapters) are missing and we will release an available version working with transformers and
torch in the next few days.~~

Now we released a beta version with Transformers Adapter working with PyTorch. The adapter is generated by Junie and
we are still in working on the modification for a stable version. Keep waiting for a beta versionğŸ¤—ğŸ¤—ğŸ¤—

## åˆæ¬¡ä½¿ç”¨ (ä»¥åŸºäº Transformers çš„ PyTorch é€‚é…å™¨ä¸ºä¾‹)

é¦–å…ˆ, åœ¨ä½ çš„åº”ç”¨ä¸­, ä½ éœ€è¦åˆ›å»ºä¸€ä¸ª `ReasoningThread`(`rt`) å¯¹è±¡å’Œä¸€ä¸ª RiCA åº”ç”¨ç¨‹åº, ç‰¹åˆ«åœ°, Transformers (PyTorch) çš„ RT
éœ€è¦é¢å¤–ä¼ å…¥æ¨¡å‹åç§° (é»˜è®¤ä¸º `google/gemma-3-1n`)ï¼š

```python
from rica import RiCA
from rica.connector import transformer_adapter as tf


app = RiCA()

rt = tf.ReasoningThread(model_name="google/gemma-3-1n")
```

è¿™æ ·, ä½ å°±æ‹¥æœ‰äº†ä¸€ä¸ª "çº¿ç¨‹". æ˜¾ç„¶, è¿™ä¸ª"çº¿ç¨‹"å½“å‰æ˜¯å†»ç»“çŠ¶æ€, æˆ‘ä»¬éœ€è¦æ¿€æ´»å®ƒ, ä¸ºæ­¤, æˆ‘ä»¬å¯ä»¥ä¼ å…¥ä¸€äº›è¯·æ±‚. ä¸å¤§éƒ¨åˆ†å¸¸ç”¨çš„äº¤äº’æ–¹å¼ä¸åŒ,
RiCA çš„æ‰€æœ‰åŒå‘çš„ä¿¡æ¯æ²Ÿé€šéƒ½æ˜¯é€šè¿‡ä½¿ç”¨å·¥å…·å®ç°çš„. RT æä¾›äº†ä¸€ä¸ªå†…å»ºæ–¹æ³•ç”¨äºå‘æ¨¡å‹ä¼ å…¥å‚æ•°, åŒæ—¶æä¾›ä½¿ç”¨ RT çš„ `@trigger` è£…é¥°ä¸€ä¸ªå›è°ƒå‡½æ•°,
ç”¨äºæ¨¡å‹å‘å¤–éƒ¨å‘é€æ¶ˆæ¯:

```python
@rt.trigger
def callback(message):
    print(message)
```

æ¼”ç¤ºæ–¹ä¾¿, æˆ‘ä»¬ä¸å¦¨æ–°å»ºä¸€ä¸ªç®€å•çš„ Python Exec çš„åŒ… (`package`) æ¥æµ‹è¯•:

```python
@app.register("sys.python.exec", True, 1000)
async def _sys_python_exec(input_, *args, **kwargs):
    """
    A tool to execute Python code.
    input:{"code": "1+1"}
    output:{"result": "2"}
    """
    try:
        code = input_.get("code", "")
        result = eval(code)
        return {"result": str(result)}
    except Exception as e:
        return {"error": str(e)}
```

å…¶ä¸­, `register` éœ€è¦ä¼ å…¥è‡³å°‘ä¸€ä¸ªï¼Œè‡³å¤šä¸‰ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯ åŒ…å (`package`), æ˜¯å¦åå°æ‰§è¡Œ (`background`) (é€šå¸¸æƒ…å†µä¸‹, é™¤äº†å¦‚å“åº”ä¿¡æ¯ä¸€ç±»çš„,
æˆ‘ä»¬å»ºè®®è®¾å®šä¸º `True` æˆ–ä½¿ç”¨ç¼ºçœå€¼) å’Œ è¶…æ—¶æ—¶é—´ (`timeout`) (å•ä½æ¯«ç§’). ä¸€åˆ‡å‡†å¤‡å°±ç»ªï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹å‘æ¨¡å‹å‘èµ·è¯·æ±‚äº†

```python
    rt.insert("Please calculate 123*456 using `sys.python.exec` package.")
rt.wait()
print(rt.context)
rt.destroy()
```

è¿™é‡Œçš„ `wait` æ˜¯ç­‰å¾…æ¨¡å‹ä¸­æ­¢ (ç”Ÿæˆ `EOS` æ ‡è®°). åœ¨æ¨¡å‹ç”Ÿæˆè¿‡ç¨‹ä¸­, ä½ æ€»æ˜¯èƒ½éšæ—¶ä¿®æ”¹ RiCA ç±», éšæ—¶æ’å…¥æ–°çš„æŒ‡ä»¤,
éšæ—¶æ‰“å°ä¸Šä¸‹æ–‡ç”šè‡³å¼ºåˆ¶å˜æ›´ä¸Šä¸‹æ–‡, ä¸€åˆ‡ç”±ä½ å†³å®š.

æ›´è¯¦ç»†çš„æ–‡æ¡£, æˆ‘ä»¬å°†å°½å¿«å®Œæˆ, æ„Ÿè°¢æ‚¨çš„æ”¯æŒ
